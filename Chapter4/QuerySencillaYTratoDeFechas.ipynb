{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8ed548-dd88-407b-9df8-fe6727c0fa28",
   "metadata": {},
   "source": [
    "# Capítulo 4: Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "6986a769-b57d-4d61-bd56-4ab238b84c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.{functions=>F}\n",
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.types.DateType\n",
       "import org.apache.spark.sql.Dataset\n",
       "import org.apache.spark.sql.functions.{asc, col, desc}\n",
       "defined class AverageDelay\n"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.{functions => F}\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.types.DateType\n",
    "import org.apache.spark.sql.Dataset\n",
    "import org.apache.spark.sql.functions.{asc, col, desc}\n",
    "case class AverageDelay (origin: String, averageDelay: Double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4028df94-95b2-4732-a614-98d623ca7aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@64fd0ec4\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder.appName(\"Ejemplo\").getOrCreate()\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ae275-9a38-4354-bff3-518453986476",
   "metadata": {},
   "source": [
    "#### Observemos que guardamos ds como un DataSet de acuerdo con la clase definida anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5c842270-fcb6-41e8-9739-0beb4e86fc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|origin|      averageDelay|\n",
      "+------+------------------+\n",
      "|   GEG| 6.068493150684931|\n",
      "|   BUR| 8.316794644615081|\n",
      "|   GRB|   8.4463480613165|\n",
      "|   GTF| 4.741176470588235|\n",
      "|   GRR|15.304448742746615|\n",
      "+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----+--------+------+-----------+\n",
      "|date   |delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|3312359|-1   |2090    |ANC   |DEN        |\n",
      "|3312359|0    |1628    |SEA   |IAH        |\n",
      "|3312359|6    |1604    |SFO   |ORD        |\n",
      "|3312359|5    |1501    |SLC   |CLT        |\n",
      "|3312359|39   |1859    |SFO   |ATL        |\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [date: int, delay: int ... 3 more fields]\n",
       "ds: org.apache.spark.sql.Dataset[AverageDelay] = [origin: string, averageDelay: double]\n"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.format(\"csv\").option(\"inferSchema\",\"true\").option(\"header\",\"true\").load(\"departuredelays.csv\")\n",
    "val ds = df.groupBy(col(\"origin\")).agg(F.avg(col(\"delay\")) as \"averageDelay\").as[AverageDelay]\n",
    "ds.show(5)\n",
    "df.orderBy(desc(\"date\")).show(5, truncate=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22dbdbc-8d42-4bb7-b86e-bdcfe02104a7",
   "metadata": {},
   "source": [
    "#### Creamos una view temporal de cada conjunto de datos. Como vemos no se encuentra ningún conflicto al crear la view desde un DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "b7c397cd-a4a6-4274-9e8a-ee6f0bb10a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: integer (nullable = true)\n",
      " |-- delay: integer (nullable = true)\n",
      " |-- distance: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")\n",
    "ds.createOrReplaceTempView(\"delayAverageByOrigin\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1b8aee06-4bd3-468c-aa5a-322ef75a86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    " //spark.sql(\"\"\"SELECT origin, delay FROM us_delay_flights_tbl WHERE origin LIKE \"%Y%\" GROUP BY origin ORDER BY origin desc\"\"\").show(5)//Sirve tanto \"...\" como \"\"\"...\"\"\"\n",
    "//pero observemos que el modo \"\"\"...\"\"\" tiene su virtud, al poder introducir \"...\" dentro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b5416-d28c-4f6f-a23c-ea66286294db",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Y hacemos una prueba con un par de consultas sencillas, de manera que siguiendo caminos distintos llegamos al mismo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "42b467e7-110d-4895-8a33-a08252f593ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|origin|       averageDelay|\n",
      "+------+-------------------+\n",
      "|   YAK| -6.685393258426966|\n",
      "|   CDV| -5.752808988764045|\n",
      "|   GFK| -5.333333333333333|\n",
      "|   FAI|  -2.95935960591133|\n",
      "|   OTZ|-2.8813559322033897|\n",
      "+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+-------------------+\n",
      "|origin|       averageDelay|\n",
      "+------+-------------------+\n",
      "|   YAK| -6.685393258426966|\n",
      "|   CDV| -5.752808988764045|\n",
      "|   GFK| -5.333333333333333|\n",
      "|   FAI|  -2.95935960591133|\n",
      "|   OTZ|-2.8813559322033897|\n",
      "+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT origin, AVG(delay) as averageDelay FROM us_delay_flights_tbl GROUP BY origin ORDER BY averageDelay asc\").show(5)\n",
    "spark.sql(\"\"\"SELECT origin, averageDelay FROM delayAverageByOrigin ORDER BY averageDelay asc\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36226821-26b3-48fb-93c0-9cb12eb1c800",
   "metadata": {},
   "source": [
    "#### Nos encontramos con una bondad de usar Spark SQL, y es que toda consulta hecha con spark.sql(\"consulta\") devuelve un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b3914f6e-97b7-42ef-8898-5fc2a8db03c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a: org.apache.spark.sql.DataFrame = [count(averageDelay): bigint]\n"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val a = spark.sql(\"\"\"SELECT COUNT(averageDelay) FROM delayAverageByOrigin WHERE averageDelay > -0.5 AND averageDelay < 0.5\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "98bf61ec-1146-4688-8328-0af16fb62da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b: Long = 6\n"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val b =ds.where(col(\"averageDelay\") > -0.5 && col(\"averageDelay\") < 0.5).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98eb63a-6fa2-46be-a9a7-1762ba9315a9",
   "metadata": {},
   "source": [
    "#### Lo verificamos en las anteriores consultas, equivalentes pero con una salida en forma de DataFrame en el caso de usar Spark SQL y un Long en otro caso. Verificamos que efectivamente la consulta da como resultado lo mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7cc92a1f-aba8-4d2d-9a1f-6aacc76706b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|count(averageDelay)|\n",
      "+-------------------+\n",
      "|                  6|\n",
      "+-------------------+\n",
      "\n",
      "6"
     ]
    }
   ],
   "source": [
    "a.show()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed294216-78ca-4d5e-8be8-5b31947d9013",
   "metadata": {},
   "source": [
    "#### Al ser objetos distintos la forma de mostrar por pantalla también dista de ser igual. Parece lógico pensar que que esto podría tener algún impacto en la eficiencia.\n",
    "#### Probemos con consultas más complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "3dd67b29-ee3a-4c27-bca6-5593ce9e74ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+------+-----------+\n",
      "|   date|delay|origin|destination|\n",
      "+-------+-----+------+-----------+\n",
      "|2190925| 1638|   SFO|        ORD|\n",
      "|1031755|  396|   SFO|        ORD|\n",
      "|1022330|  326|   SFO|        ORD|\n",
      "|1051205|  320|   SFO|        ORD|\n",
      "|1190925|  297|   SFO|        ORD|\n",
      "|2171115|  296|   SFO|        ORD|\n",
      "|1071040|  279|   SFO|        ORD|\n",
      "|1051550|  274|   SFO|        ORD|\n",
      "|3120730|  266|   SFO|        ORD|\n",
      "|1261104|  258|   SFO|        ORD|\n",
      "+-------+-----+------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT date, delay, origin, destination  \n",
    "FROM us_delay_flights_tbl  \n",
    "WHERE delay > 120 AND ORIGIN = 'SFO' AND DESTINATION = 'ORD'  \n",
    "ORDER by delay DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "bb419ebd-0c69-45fc-af93-2a907befd7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----------+-------------+\n",
      "|delay|origin|destination|Flight_Delays|\n",
      "+-----+------+-----------+-------------+\n",
      "|  333|   ABE|        ATL|  Long Delays|\n",
      "|  305|   ABE|        ATL|  Long Delays|\n",
      "|  275|   ABE|        ATL|  Long Delays|\n",
      "|  257|   ABE|        ATL|  Long Delays|\n",
      "|  247|   ABE|        DTW|  Long Delays|\n",
      "|  247|   ABE|        ATL|  Long Delays|\n",
      "|  219|   ABE|        ORD|  Long Delays|\n",
      "|  211|   ABE|        ATL|  Long Delays|\n",
      "|  197|   ABE|        DTW|  Long Delays|\n",
      "|  192|   ABE|        ORD|  Long Delays|\n",
      "+-----+------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT delay, origin, destination, \n",
    " CASE \n",
    " WHEN delay > 360 THEN 'Very Long Delays' \n",
    " WHEN delay > 120 AND delay < 360 THEN 'Long Delays' \n",
    " WHEN delay > 60 AND delay < 120 THEN 'Short Delays' \n",
    " WHEN delay > 0 and delay < 60 THEN 'Tolerable Delays' \n",
    " WHEN delay = 0 THEN 'No Delays' \n",
    " ELSE 'Early' \n",
    " END AS Flight_Delays \n",
    " FROM us_delay_flights_tbl \n",
    " ORDER BY origin, delay DESC\"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e5958-132b-4682-80b8-c77be5a8781a",
   "metadata": {},
   "source": [
    "#### Procedemos a tratar la fecha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45d5e5-c97e-40ec-836b-0fa0e8247ebd",
   "metadata": {},
   "source": [
    "Se ha observado que 0111 es leido como 111 así que sumamos lo necesario para conseguir 10111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "581e6bf5-0fa8-4d18-8f17-3d94fe896b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+------+-----------+---------+\n",
      "|delay|distance|origin|destination|     date|\n",
      "+-----+--------+------+-----------+---------+\n",
      "|    6|     602|   ABE|        ATL|101011245|\n",
      "|   -8|     369|   ABE|        DTW|101020600|\n",
      "|   -2|     602|   ABE|        ATL|101021245|\n",
      "|   -4|     602|   ABE|        ATL|101020605|\n",
      "|   -4|     602|   ABE|        ATL|101031245|\n",
      "|    0|     602|   ABE|        ATL|101030605|\n",
      "|   10|     602|   ABE|        ATL|101041243|\n",
      "|   28|     602|   ABE|        ATL|101040605|\n",
      "|   88|     602|   ABE|        ATL|101051245|\n",
      "|    9|     602|   ABE|        ATL|101050605|\n",
      "|   -6|     602|   ABE|        ATL|101061215|\n",
      "|   69|     602|   ABE|        ATL|101061725|\n",
      "|    0|     369|   ABE|        DTW|101061230|\n",
      "|   -3|     602|   ABE|        ATL|101060625|\n",
      "|    0|     369|   ABE|        DTW|101070600|\n",
      "|    0|     602|   ABE|        ATL|101071725|\n",
      "|    0|     369|   ABE|        DTW|101071230|\n",
      "|    0|     602|   ABE|        ATL|101070625|\n",
      "|    0|     569|   ABE|        ORD|101071219|\n",
      "|    0|     369|   ABE|        DTW|101080600|\n",
      "+-----+--------+------+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT delay, distance, origin, destination,cast((date+100000000) as char(30)) as date FROM us_delay_flights_tbl\"\"\").createOrReplaceTempView(\"us_delay_flights_tblAUX\")\n",
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "952c304f-4490-4894-8afe-a3f66b0e30ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "//Por qué no me deja guardarlo como \"us_delay_flights_tblAUX\"?\n",
    "spark.sql(\"\"\"SELECT date, SUBSTRING(date, 2,2) as month,SUBSTRING(date, 4,2) as day, SUBSTRING(date, 6,2) as hour, SUBSTRING(date, 8,2) as min\n",
    "FROM us_delay_flights_tblAUX\"\"\").createOrReplaceTempView(\"us_delay_flights_tblAUX1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de612e6-51a4-49b4-bc2d-a77c6241aa5a",
   "metadata": {},
   "source": [
    "#### Éxito al convertir la fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "19a35aec-57ac-4b69-9e4a-0a52233a7e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+----+---+\n",
      "|     date|month|day|hour|min|\n",
      "+---------+-----+---+----+---+\n",
      "|101011245|   01| 01|  12| 45|\n",
      "|101020600|   01| 02|  06| 00|\n",
      "|101021245|   01| 02|  12| 45|\n",
      "|101020605|   01| 02|  06| 05|\n",
      "|101031245|   01| 03|  12| 45|\n",
      "|101030605|   01| 03|  06| 05|\n",
      "|101041243|   01| 04|  12| 43|\n",
      "|101040605|   01| 04|  06| 05|\n",
      "|101051245|   01| 05|  12| 45|\n",
      "|101050605|   01| 05|  06| 05|\n",
      "|101061215|   01| 06|  12| 15|\n",
      "|101061725|   01| 06|  17| 25|\n",
      "|101061230|   01| 06|  12| 30|\n",
      "|101060625|   01| 06|  06| 25|\n",
      "|101070600|   01| 07|  06| 00|\n",
      "|101071725|   01| 07|  17| 25|\n",
      "|101071230|   01| 07|  12| 30|\n",
      "|101070625|   01| 07|  06| 25|\n",
      "|101071219|   01| 07|  12| 19|\n",
      "|101080600|   01| 08|  06| 00|\n",
      "+---------+-----+---+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX1\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c98d0fd-e49e-489a-8d69-6fa000cafa67",
   "metadata": {},
   "source": [
    "#### Creamos una tabla conjunta suponiendo que la tabla corresponde a los vuelos de 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "32c1928d-8456-4c64-994b-e8bbc7e970f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+------+---------------+-----+--------+------+-----------+\n",
      "|month|day|hour|minute|           DATE|delay|distance|origin|destination|\n",
      "+-----+---+----+------+---------------+-----+--------+------+-----------+\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    6|     602|   ABE|        ATL|\n",
      "|    1|  2|   6|     0|  20/1/2 6:0:00|   -8|     369|   ABE|        DTW|\n",
      "|    1|  2|  12|    45|20/1/2 12:45:00|   -2|     602|   ABE|        ATL|\n",
      "|    1|  2|   6|     5|  20/1/2 6:5:00|   -4|     602|   ABE|        ATL|\n",
      "|    1|  3|  12|    45|20/1/3 12:45:00|   -4|     602|   ABE|        ATL|\n",
      "|    1|  3|   6|     5|  20/1/3 6:5:00|    0|     602|   ABE|        ATL|\n",
      "|    1|  4|  12|    43|20/1/4 12:43:00|   10|     602|   ABE|        ATL|\n",
      "|    1|  4|   6|     5|  20/1/4 6:5:00|   28|     602|   ABE|        ATL|\n",
      "|    1|  5|  12|    45|20/1/5 12:45:00|   88|     602|   ABE|        ATL|\n",
      "|    1|  5|   6|     5|  20/1/5 6:5:00|    9|     602|   ABE|        ATL|\n",
      "|    1|  6|  12|    15|20/1/6 12:15:00|   -6|     602|   ABE|        ATL|\n",
      "|    1|  6|  17|    25|20/1/6 17:25:00|   69|     602|   ABE|        ATL|\n",
      "|    1|  6|  12|    30|20/1/6 12:30:00|    0|     369|   ABE|        DTW|\n",
      "|    1|  6|   6|    25| 20/1/6 6:25:00|   -3|     602|   ABE|        ATL|\n",
      "|    1|  7|   6|     0|  20/1/7 6:0:00|    0|     369|   ABE|        DTW|\n",
      "|    1|  7|  17|    25|20/1/7 17:25:00|    0|     602|   ABE|        ATL|\n",
      "|    1|  7|  12|    30|20/1/7 12:30:00|    0|     369|   ABE|        DTW|\n",
      "|    1|  7|   6|    25| 20/1/7 6:25:00|    0|     602|   ABE|        ATL|\n",
      "|    1|  7|  12|    19|20/1/7 12:19:00|    0|     569|   ABE|        ORD|\n",
      "|    1|  8|   6|     0|  20/1/8 6:0:00|    0|     369|   ABE|        DTW|\n",
      "+-----+---+----+------+---------------+-----+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT cast(SUBSTRING(date, 2,2) as INTEGER) as month, cast(SUBSTRING(date, 4,2) as INTEGER) as day, cast(SUBSTRING(date, 6,2) as INTEGER) as hour, cast(SUBSTRING(date, 8,2) as INTEGER) as minute,\n",
    "concat(\"20/\",cast(SUBSTRING(date, 2,2) as INTEGER),\"/\",cast(SUBSTRING(date, 4,2) as INTEGER),\" \", cast(SUBSTRING(date, 6,2) as INTEGER),\":\", cast(SUBSTRING(date, 8,2) as INTEGER),\":00\") as DATE, delay, distance, origin, destination\n",
    "FROM us_delay_flights_tblAUX\"\"\").createOrReplaceTempView(\"us_delay_flights_tblAUX2\")\n",
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX2\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daf0351-8a0c-43d6-8886-18482bcd9e5e",
   "metadata": {},
   "source": [
    "###### Observemos que puede ser interesante combinar las dos formas de consultar. Por ejemplo en este caso para contar el número de vuelos en un preciso instante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "7d2385ef-d0e9-4134-82ab-fa899197acf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+------+---------------+-----+--------+------+-----------+\n",
      "|month|day|hour|minute|           DATE|delay|distance|origin|destination|\n",
      "+-----+---+----+------+---------------+-----+--------+------+-----------+\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    6|     602|   ABE|        ATL|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   22|     636|   ATL|        DFW|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -4|     505|   ATL|        FLL|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -1|     662|   ATL|        LGA|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    3|     633|   BOS|        CLT|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -4|     819|   BOS|        BNA|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   32|     311|   BUR|        SMF|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   14|     257|   BUR|        SJC|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -3|     355|   BWI|        DTW|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    3|     321|   BWI|        BOS|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -4|     410|   BWI|        CHS|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|  -14|     861|   CAK|        RSW|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    4|     845|   CMH|        FLL|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   52|     778|   DEN|        MDW|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    2|    1404|   DFW|        PDX|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   14|     392|   EUG|        SFO|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    0|    1226|   EWR|        HOU|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -4|     287|   FAY|        ATL|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    9|     972|   FLL|        DFW|\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|   -3|     505|   FLL|        ATL|\n",
      "+-----+---+----+------+---------------+-----+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "res566: Long = 52\n"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX2 WHERE month == 1 AND day == 1 AND hour==12 AND minute==45\"\"\").show()\n",
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX2 WHERE month == 1 AND day == 1 AND hour==12 AND minute==45\"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0b128-1a8b-4f16-9c6f-1aec5c57a048",
   "metadata": {},
   "source": [
    "#### Vayamos a consulta propuesta en el libro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e2b1d-7513-431f-8e58-cd1cddbc81e4",
   "metadata": {},
   "source": [
    "Nos pide ver en qué época del año hay mayor delay. Parece lógico juntar todo lo visto hasta ahora. Por un lado las fechas bien puestas y por \n",
    "el otro lado una etiqueta a cada delay. Así podremos agrupar por tipo de delay y contar el número de tipos de delay. Para sacar así una conclusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "572f3fb4-35e7-4df0-9c7f-7c7d0bdb5f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+------+---------------+-----+----------------+--------+------+-----------+\n",
      "|month|day|hour|minute|           DATE|delay|   Flight_Delays|distance|origin|destination|\n",
      "+-----+---+----+------+---------------+-----+----------------+--------+------+-----------+\n",
      "|    1|  1|  12|    45|20/1/1 12:45:00|    6|Tolerable Delays|     602|   ABE|        ATL|\n",
      "|    1|  2|   6|     0|  20/1/2 6:0:00|   -8|           Early|     369|   ABE|        DTW|\n",
      "|    1|  2|  12|    45|20/1/2 12:45:00|   -2|           Early|     602|   ABE|        ATL|\n",
      "|    1|  2|   6|     5|  20/1/2 6:5:00|   -4|           Early|     602|   ABE|        ATL|\n",
      "|    1|  3|  12|    45|20/1/3 12:45:00|   -4|           Early|     602|   ABE|        ATL|\n",
      "|    1|  3|   6|     5|  20/1/3 6:5:00|    0|       No Delays|     602|   ABE|        ATL|\n",
      "|    1|  4|  12|    43|20/1/4 12:43:00|   10|Tolerable Delays|     602|   ABE|        ATL|\n",
      "|    1|  4|   6|     5|  20/1/4 6:5:00|   28|Tolerable Delays|     602|   ABE|        ATL|\n",
      "|    1|  5|  12|    45|20/1/5 12:45:00|   88|    Short Delays|     602|   ABE|        ATL|\n",
      "|    1|  5|   6|     5|  20/1/5 6:5:00|    9|Tolerable Delays|     602|   ABE|        ATL|\n",
      "|    1|  6|  12|    15|20/1/6 12:15:00|   -6|           Early|     602|   ABE|        ATL|\n",
      "|    1|  6|  17|    25|20/1/6 17:25:00|   69|    Short Delays|     602|   ABE|        ATL|\n",
      "|    1|  6|  12|    30|20/1/6 12:30:00|    0|       No Delays|     369|   ABE|        DTW|\n",
      "|    1|  6|   6|    25| 20/1/6 6:25:00|   -3|           Early|     602|   ABE|        ATL|\n",
      "|    1|  7|   6|     0|  20/1/7 6:0:00|    0|       No Delays|     369|   ABE|        DTW|\n",
      "|    1|  7|  17|    25|20/1/7 17:25:00|    0|       No Delays|     602|   ABE|        ATL|\n",
      "|    1|  7|  12|    30|20/1/7 12:30:00|    0|       No Delays|     369|   ABE|        DTW|\n",
      "|    1|  7|   6|    25| 20/1/7 6:25:00|    0|       No Delays|     602|   ABE|        ATL|\n",
      "|    1|  7|  12|    19|20/1/7 12:19:00|    0|       No Delays|     569|   ABE|        ORD|\n",
      "|    1|  8|   6|     0|  20/1/8 6:0:00|    0|       No Delays|     369|   ABE|        DTW|\n",
      "+-----+---+----+------+---------------+-----+----------------+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT cast(SUBSTRING(date, 2,2) as INTEGER) as month, cast(SUBSTRING(date, 4,2) as INTEGER) as day, cast(SUBSTRING(date, 6,2) as INTEGER) as hour, cast(SUBSTRING(date, 8,2) as INTEGER) as minute,\n",
    "concat(\"20/\",cast(SUBSTRING(date, 2,2) as INTEGER),\"/\",cast(SUBSTRING(date, 4,2) as INTEGER),\" \", cast(SUBSTRING(date, 6,2) as INTEGER),\":\", cast(SUBSTRING(date, 8,2) as INTEGER),\":00\") as DATE, delay,CASE \n",
    " WHEN delay > 360 THEN 'Very Long Delays' \n",
    " WHEN delay > 120 AND delay < 360 THEN 'Long Delays' \n",
    " WHEN delay > 60 AND delay < 120 THEN 'Short Delays' \n",
    " WHEN delay > 0 and delay < 60 THEN 'Tolerable Delays' \n",
    " WHEN delay = 0 THEN 'No Delays' \n",
    " ELSE 'Early' \n",
    " END AS Flight_Delays  ,distance, origin, destination\n",
    "FROM us_delay_flights_tblAUX\"\"\").createOrReplaceTempView(\"us_delay_flights_tblAUX3\")\n",
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX3\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "0de7b7ab-4001-4939-b2b0-3a364fb6e915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|month|VeryLongDelay|\n",
      "+-----+-------------+\n",
      "|    1|          735|\n",
      "|    2|          433|\n",
      "|    3|          331|\n",
      "+-----+-------------+\n",
      "\n",
      "+-----+---------+\n",
      "|month|LongDelay|\n",
      "+-----+---------+\n",
      "|    1|    14058|\n",
      "|    2|     9533|\n",
      "|    3|     7836|\n",
      "+-----+---------+\n",
      "\n",
      "+-----+------+\n",
      "|month| Early|\n",
      "+-----+------+\n",
      "|    1|207257|\n",
      "|    2|201005|\n",
      "|    3|263023|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT month, count(Flight_Delays) as VeryLongDelay FROM us_delay_flights_tblAUX3 WHERE Flight_Delays == \"Very Long Delays\" GROUP BY month\"\"\").show(360)\n",
    "spark.sql(\"\"\"SELECT month, count(Flight_Delays) as LongDelay FROM us_delay_flights_tblAUX3 WHERE Flight_Delays == \"Long Delays\" GROUP BY month\"\"\").show(360)\n",
    "spark.sql(\"\"\"SELECT month, count(Flight_Delays) as Early FROM us_delay_flights_tblAUX3 WHERE Flight_Delays == \"Early\" GROUP BY month\"\"\").show(360)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7012862-335c-443e-9735-f22a5a664bf1",
   "metadata": {},
   "source": [
    "#### Como podemos observar no se tiene el fichero completo. Faltan todos los meses desde abril hasta diciembre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "68bebe03-07db-4cd0-a3f9-bb298c23920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+------+----------------+-----+----------------+--------+------+-----------+\n",
      "|month|day|hour|minute|            DATE|delay|   Flight_Delays|distance|origin|destination|\n",
      "+-----+---+----+------+----------------+-----+----------------+--------+------+-----------+\n",
      "|    1|  7|  23|    59| 20/1/7 23:59:00|   14|Tolerable Delays|    1586|   ABQ|        JFK|\n",
      "|    1| 14|  23|    59|20/1/14 23:59:00|  -17|           Early|    1586|   ABQ|        JFK|\n",
      "|    1| 21|  23|    59|20/1/21 23:59:00|    0|       No Delays|    1586|   ABQ|        JFK|\n",
      "|    1| 28|  23|    59|20/1/28 23:59:00|  -20|           Early|    1586|   ABQ|        JFK|\n",
      "|    1|  2|  23|    59| 20/1/2 23:59:00|   20|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1|  3|  23|    59| 20/1/3 23:59:00|   36|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1|  4|  23|    59| 20/1/4 23:59:00| 1033|Very Long Delays|    2090|   ANC|        DEN|\n",
      "|    1|  5|  23|    59| 20/1/5 23:59:00|   42|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1|  6|  23|    59| 20/1/6 23:59:00|   -4|           Early|    2090|   ANC|        DEN|\n",
      "|    1|  7|  23|    59| 20/1/7 23:59:00|   32|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1|  8|  23|    59| 20/1/8 23:59:00|   -4|           Early|    2090|   ANC|        DEN|\n",
      "|    1|  9|  23|    59| 20/1/9 23:59:00|   26|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 10|  23|    59|20/1/10 23:59:00|   16|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 11|  23|    59|20/1/11 23:59:00|   22|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 12|  23|    59|20/1/12 23:59:00|   34|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 13|  23|    59|20/1/13 23:59:00|   32|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 14|  23|    59|20/1/14 23:59:00|   20|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 15|  23|    59|20/1/15 23:59:00|    7|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 16|  23|    59|20/1/16 23:59:00|   24|Tolerable Delays|    2090|   ANC|        DEN|\n",
      "|    1| 17|  23|    59|20/1/17 23:59:00|   -8|           Early|    2090|   ANC|        DEN|\n",
      "+-----+---+----+------+----------------+-----+----------------+--------+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tblAUX3 WHERE minute==59\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b5d49-2ad3-4be0-a6c5-a08defbc7f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
