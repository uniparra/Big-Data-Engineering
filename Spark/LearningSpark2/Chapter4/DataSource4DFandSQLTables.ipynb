{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587c58ec-a2d9-4b83-8357-51084c73c624",
   "metadata": {},
   "source": [
    "  ## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a73f7e1-e795-4611-8012-8fece79eb16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "import org.apache.spark.sql.DataFrameWriter\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.DataFrameWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0bde3d0-0cf1-41ff-8b0f-590bd6d7883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@45719e9e\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder.appName(\"Read\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b39f10-ac70-4f4b-87d0-cc125ea5cbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW ejemplo USING parquet OPTIONS(path \"ejemplo.parquet\")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f855541-b4d6-4f0f-b4c7-6dd639226e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4359ec1d-c9a6-4983-91af-8fdce6a4e30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|ageModif|\n",
      "+------+--------+\n",
      "|Brooke|      40|\n",
      "| Brook|      43|\n",
      "| Jules|      50|\n",
      "| Denny|      51|\n",
      "|    TD|      55|\n",
      "+------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ejDF: org.apache.spark.sql.DataFrame = [name: string, ageModif: int]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ejDF=spark.sql(\"\"\"SELECT name, (age+20) as ageModif FROM ejemplo\"\"\")\n",
    "ejDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcc021-1b05-45ec-bb5f-123dce139608",
   "metadata": {},
   "source": [
    "Esto nos genera un conjunto de ficheros compactos y comprimidos parquet en el path especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17320448-b2de-4b60-8ee8-0759c96a5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejDF.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\",\"snappy\").save(\"ejemploModif.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17137cc5-48c1-4fd7-b98c-62083558399b",
   "metadata": {},
   "source": [
    "Bucketing es una técnica para descomponer conjuntos de datos en partes más manejables. Por ejemplo, supongamos que una tabla en que se usa \"date\" como partición de nivel superior y \"employee_id\" como partición de segundo nivel genera demasiadas particiones pequeñas. En cambio, si clasificamos la tabla de empleados y usamos \"employee_id\" como columna de clasificación, el valor de esta columna se dividirá mediante un número definido por el usuario en depósitos. Los registros con el mismo \"employee_id\" siempre se almacenarán en el mismo cubo. Suponiendo que la cantidad de employee_ides mucho mayor que la cantidad de cubos, cada cubo tendrá muchos employee_id. Al crear la tabla, puede especificar como (en HQL) \"CLUSTERED BY (employee_id) INTO XX  BUCKETS\"; donde XX es el número de cubos. El agrupamiento tiene varias ventajas. El número de cubos es fijo para que no fluctúe con los datos. Si dos tablas están agrupadas por employee_id, Hive puede crear un muestreo lógicamente correcto. La agrupación también ayuda a realizar uniones eficientes en el lado del mapa, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b2a1a676-3773-4664-811d-eedc3b33cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejDF.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\",\"snappy\").bucketBy(2,\"name\").saveAsTable(\"ejemploModifi.parquet\")\n",
    "ejDF.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\",\"snappy\").partitionBy(\"name\").save(\"ejemploModifi.parquet\")\n",
    "ejDF.repartition(2, col(\"name\")).write.format(\"csv\").mode(\"overwrite\").option(\"path\", \"ipaÇ\").bucketBy(2,\"name\").saveAsTable(\"ejemploModifii.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "55dc4fb2-b882-4089-b444-17c7c9ec7b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejDF.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\",\"snappy\").bucketBy(2,\"name\").save(\"ejemploModifi.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e3faba21-4e13-4cd5-9825-657fec615dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejDF.write.format(\"parquet\").mode(\"overwrite\").option(\"compression\",\"snappy\").bucketBy(2,\"name\").saveAsTable(\"ejemploModif.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218fdadc-a82d-4276-a683-b4c2fddc76a1",
   "metadata": {},
   "source": [
    "bucketBy() no funciona en este entorno...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bc713e8e-6707-44a1-b2b0-741819dcccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejDF.write.mode(\"overwrite\").saveAsTable(\"ejemploModificado.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff0fec-54e5-4233-80dc-6817c94c46a8",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c655c645-c65e-4d65-a962-6e7bcca416bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejDF.write.format(\"json\").mode(\"overwrite\").option(\"compresseion\",\"snappy\").save(\"ejemploJsonDelays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84bf260e-480c-4762-af89-42819fb6b60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eJsonDF: org.apache.spark.sql.DataFrame = [ageModif: bigint, name: string]\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val eJsonDF = spark.read.format(\"json\").load(\"ejemploJsonDelays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "944b03cc-35fc-4625-a6ed-94c2ba2d9b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|ageModif|  name|\n",
      "+--------+------+\n",
      "|      40|Brooke|\n",
      "|      43| Brook|\n",
      "|      51| Denny|\n",
      "|      50| Jules|\n",
      "|      55|    TD|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eJsonDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4699e-2047-42ab-99f9-6d958915dbe7",
   "metadata": {},
   "source": [
    "se puede elegir el formato de codificacion .option(\"charset\", \"UTF-16BE\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03940d92-9827-48d7-9c9d-922ebfc739e4",
   "metadata": {},
   "source": [
    "Podemos también crear View's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2471498d-06a6-47e6-a5a5-041c9123e151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|ageModif|  name|\n",
      "+--------+------+\n",
      "|      40|Brooke|\n",
      "|      43| Brook|\n",
      "|      51| Denny|\n",
      "|      50| Jules|\n",
      "|      55|    TD|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW ejemplo USING json OPTIONS(path \"ejemploJsonDelays\")\"\"\")\n",
    "spark.sql(\"SELECT * FROM ejemplo\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a236c4ef-56d5-4e6e-83a0-fee4831f1879",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6b744-9870-4578-b5be-563df655468e",
   "metadata": {},
   "source": [
    "El modo PERMISSIVE establece valores de campo nulos cuando se detectan registros corruptos. De manera predeterminada, si no especifica el modo de parámetro, Spark establece el valor PERMISSION.\n",
    "\n",
    "El modo DROPMALFORMED ignora los registros corruptos. Lo que significa que, si elige este tipo de modo, los registros corruptos no aparecerán en la lista.\n",
    "\n",
    "A diferencia del modo DROPMALFORMED y PERMISSIVE, FAILFAST lanza una excepción cuando detecta registros dañados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "39541a13-c0b6-4e08-bad2-b5343c5275b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ejCSV: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ejCSV = spark.read.format(\"csv\").schema(\"DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count INT\")\n",
    ".option(\"header\",\"true\")\n",
    ".option(\"nullValue\",\" \")\n",
    ".option(\"mode\",\"FAILFAST\") //Sale si se encuentra algun error\n",
    ".load(\"summaryFlightCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4df48c9d-9c9f-4224-b2ac-45d073302003",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|    1|\n",
      "|       United States|            Ireland|  264|\n",
      "|       United States|              India|   69|\n",
      "|               Egypt|      United States|   24|\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|       United States|          Singapore|   25|\n",
      "|       United States|            Grenada|   54|\n",
      "|          Costa Rica|      United States|  477|\n",
      "|             Senegal|      United States|   29|\n",
      "|       United States|   Marshall Islands|   44|\n",
      "|              Guyana|      United States|   17|\n",
      "|       United States|       Sint Maarten|   53|\n",
      "|               Malta|      United States|    1|\n",
      "|             Bolivia|      United States|   46|\n",
      "|            Anguilla|      United States|   21|\n",
      "|Turks and Caicos ...|      United States|  136|\n",
      "|       United States|        Afghanistan|    2|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  390|\n",
      "|       United States|             Russia|  156|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ejCSV.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd313e-4fcc-41ab-85d3-548ad34af25b",
   "metadata": {},
   "source": [
    "Probemos los metodos .option(\"mode\",\"FAILFAST\") y .option(nullValue, \" \") con JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b02592b-5912-45b1-a6d6-00033dbfe5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ejJSON: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ejJSON = spark.read.format(\"json\").schema(\"DEST_COUNTRY_NAME STRING, ORIGIN_COUNTRY_NAME STRING, count INT\")\n",
    ".option(\"header\",\"true\")\n",
    ".option(\"nullValue\",\" \")\n",
    ".option(\"mode\",\"PERMISSIVE\") //Sale si se encuentra algun error\n",
    ".load(\"summaryFlightJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "23943c73-7bf8-4250-936b-846cd153b7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|   15|\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|            Ireland|  344|\n",
      "|               Egypt|      United States|   15|\n",
      "|       United States|              India|   62|\n",
      "|       United States|          Singapore|    1|\n",
      "|       United States|            Grenada|   62|\n",
      "|          Costa Rica|      United States|  588|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|       Sint Maarten|  325|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|              Guyana|      United States|   64|\n",
      "|               Malta|      United States|    1|\n",
      "|            Anguilla|      United States|   41|\n",
      "|             Bolivia|      United States|   30|\n",
      "|       United States|           Paraguay|    6|\n",
      "|             Algeria|      United States|    4|\n",
      "|Turks and Caicos ...|      United States|  230|\n",
      "|       United States|          Gibraltar|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ejJSON.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95282b8e-4c9e-48d4-b2ab-6734b5afecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejJSON.repartition(9, col(\"count\")).write.format(\"json\").mode(\"overwrite\").saveAsTable(\"ejemploModifiFLIGHTJSON\")\n",
    "ejJSON.repartition(9, col(\"count\")).write.format(\"json\").mode(\"overwrite\").save(\"ejemploModifiFLIGHTJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5be4173c-a6ca-4cda-9563-66e988adad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Croatia|    1|\n",
      "|       United States|          Singapore|    1|\n",
      "|             Senegal|      United States|   40|\n",
      "|             Moldova|      United States|    1|\n",
      "|       United States|   Marshall Islands|   39|\n",
      "|               Malta|      United States|    1|\n",
      "|       United States|          Gibraltar|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|         The Bahamas|      United States|  955|\n",
      "|            Suriname|      United States|    1|\n",
      "|       United States|             Cyprus|    1|\n",
      "|       United States|           Suriname|   34|\n",
      "|       United States|              Chile|  185|\n",
      "|        Burkina Faso|      United States|    1|\n",
      "|       United States|             Poland|   33|\n",
      "|    Saint Barthelemy|      United States|   39|\n",
      "|            Djibouti|      United States|    1|\n",
      "|       United States|            Estonia|    1|\n",
      "|              Zambia|      United States|    1|\n",
      "|       United States|             Panama|  465|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM ejemploModifiFLIGHTJSON\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7faabac-df80-4c15-a19d-237ea9ebd4b8",
   "metadata": {},
   "source": [
    "También se pueden crear View's usando Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cec94f6d-11d0-49d1-9b1c-adf0fd2b38bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res82: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW summaryCSV\n",
    "USING csv\n",
    "OPTIONS (\n",
    "path \"summaryFlightCSV\",\n",
    "header \"true\",\n",
    "inferSchema \"true\",\n",
    "mode \"FAILFAST\"\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dd6a3e25-fa17-40b2-84c5-6be8506e576c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|    1|\n",
      "|       United States|            Ireland|  264|\n",
      "|       United States|              India|   69|\n",
      "|               Egypt|      United States|   24|\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|       United States|          Singapore|   25|\n",
      "|       United States|            Grenada|   54|\n",
      "|          Costa Rica|      United States|  477|\n",
      "|             Senegal|      United States|   29|\n",
      "|       United States|   Marshall Islands|   44|\n",
      "|              Guyana|      United States|   17|\n",
      "|       United States|       Sint Maarten|   53|\n",
      "|               Malta|      United States|    1|\n",
      "|             Bolivia|      United States|   46|\n",
      "|            Anguilla|      United States|   21|\n",
      "|Turks and Caicos ...|      United States|  136|\n",
      "|       United States|        Afghanistan|    2|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  390|\n",
      "|       United States|             Russia|  156|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM summaryCSV\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873f4723-c5f8-4162-beb5-69028d214992",
   "metadata": {},
   "source": [
    "## AVRO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da621126-47b3-4608-bc2a-fef62d957f07",
   "metadata": {},
   "source": [
    "Problemas con usar AVRO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "910a9646-9588-430c-b878-a95fe64f9507",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "30: error: object avro is not a member of package org.apache.spark.sql",
     "output_type": "error",
     "traceback": [
      "<console>:30: error: object avro is not a member of package org.apache.spark.sql",
      "       import org.apache.spark.sql.avro._",
      "                                   ^",
      ""
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.avro._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b31fa40-b451-416f-9fe3-ddb5400489d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": "  Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of \"Apache Avro Data Source Guide\".",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException:  Failed to find data source: avro. Avro is built-in but external data source module since Spark 2.4. Please deploy the application as per the deployment section of \"Apache Avro Data Source Guide\".",
      "  at org.apache.spark.sql.errors.QueryCompilationErrors$.failedToFindAvroDataSourceError(QueryCompilationErrors.scala:1028)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:666)",
      "  at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:720)",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)",
      "  at org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:188)",
      "  ... 41 elided",
      ""
     ]
    }
   ],
   "source": [
    "val ejAVRO = spark.read.format(\"avro\").load(\"summaryAVRO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a6af9-24b8-4850-b579-d24ec4bebbf2",
   "metadata": {},
   "source": [
    "Crear una tabla SQL usando un data source AVRO no es distinto de con PARQUET, JSON, CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99938488-0fcd-47b0-9477-abb9b13cb13b",
   "metadata": {},
   "source": [
    "## ORC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c32c1593-b98c-4ec3-8f14-e67769ec579e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ejORC: org.apache.spark.sql.DataFrame = [DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string ... 1 more field]\n"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ejORC = spark.read.format(\"orc\").load(\"ejemploORC.orc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "52b830e1-e4fd-449b-8d70-41f6c17ca281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|    1|\n",
      "|       United States|            Ireland|  264|\n",
      "|       United States|              India|   69|\n",
      "|               Egypt|      United States|   24|\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|       United States|          Singapore|   25|\n",
      "|       United States|            Grenada|   54|\n",
      "|          Costa Rica|      United States|  477|\n",
      "|             Senegal|      United States|   29|\n",
      "|       United States|   Marshall Islands|   44|\n",
      "|              Guyana|      United States|   17|\n",
      "|       United States|       Sint Maarten|   53|\n",
      "|               Malta|      United States|    1|\n",
      "|             Bolivia|      United States|   46|\n",
      "|            Anguilla|      United States|   21|\n",
      "|Turks and Caicos ...|      United States|  136|\n",
      "|       United States|        Afghanistan|    2|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  390|\n",
      "|       United States|             Russia|  156|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ejORC.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0484e262-77e9-4c20-b251-c91c0bb081b0",
   "metadata": {},
   "source": [
    "Las view funcionan exactamente igual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "95c3b530-ea99-4bdd-9350-b38250414a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res86: org.apache.spark.sql.DataFrame = []\n"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TEMPORARY VIEW summaryORC\n",
    "USING orc\n",
    "OPTIONS (\n",
    "path \"ejemploORC.orc\"\n",
    ")\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6615c6d3-6897-4501-8d0b-0755b51b4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|    1|\n",
      "|       United States|            Ireland|  264|\n",
      "|       United States|              India|   69|\n",
      "|               Egypt|      United States|   24|\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|       United States|          Singapore|   25|\n",
      "|       United States|            Grenada|   54|\n",
      "|          Costa Rica|      United States|  477|\n",
      "|             Senegal|      United States|   29|\n",
      "|       United States|   Marshall Islands|   44|\n",
      "|              Guyana|      United States|   17|\n",
      "|       United States|       Sint Maarten|   53|\n",
      "|               Malta|      United States|    1|\n",
      "|             Bolivia|      United States|   46|\n",
      "|            Anguilla|      United States|   21|\n",
      "|Turks and Caicos ...|      United States|  136|\n",
      "|       United States|        Afghanistan|    2|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|               Italy|      United States|  390|\n",
      "|       United States|             Russia|  156|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM summaryORC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af179c7a-b697-4158-837f-c27a2343bc8e",
   "metadata": {},
   "source": [
    "Y la escritura también igual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6162be3-7300-49b5-9987-9768c4edf5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ejORC.write.format(\"orc\").mode(\"overwrite\").option(\"compression\", \"snappy\").save(\"df_ORC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caabacda-c94e-425a-aa31-1bbef8f5281f",
   "metadata": {},
   "source": [
    "## IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "47fa7d42-47b2-4ab6-a432-cbcfc2a4983b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.source.image\n"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.source.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5b0f7208-4591-4fc9-89f8-16a6973f67a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "imagesDF: org.apache.spark.sql.DataFrame = [image: struct<origin: string, height: int ... 4 more fields>, label: int]\n"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val imagesDF = spark.read.format(\"image\").load(\"ejemploIMAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4e5fc312-b9e5-429d-aa58-6992bfdb02a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "99da78c2-2ffe-437e-bde0-0824558f7dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------+----+-----+\n",
      "|height|width|nChannels|mode|label|\n",
      "+------+-----+---------+----+-----+\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    1|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    1|\n",
      "|   288|  384|        3|  16|    1|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    1|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    1|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "|   288|  384|        3|  16|    0|\n",
      "+------+-----+---------+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesDF.select(\"image.height\", \"image.width\", \"image.nChannels\", \"image.mode\", \"label\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f43cc9-2824-441e-a4d8-f0ace9410c65",
   "metadata": {},
   "source": [
    "## BINARY FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae13c1f8-43aa-4d6e-a5af-968bbd2aa0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binaryFilesDF: org.apache.spark.sql.DataFrame = [path: string, modificationTime: timestamp ... 3 more fields]\n"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val binaryFilesDF = spark.read.format(\"binaryFile\")\n",
    ".option(\"pathGlobFilter\", \"*.jpg\") // le dices el tipo de formato\n",
    ".load(\"ejemploIMAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7b595870-4c49-4d94-848e-4740929a72ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+-----+\n",
      "|                path|    modificationTime|length|             content|label|\n",
      "+--------------------+--------------------+------+--------------------+-----+\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 55037|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/home/jovyan...| 2022-06-23 10:05:09| 54634|[FF D8 FF E0 00 1...|    1|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54624|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54505|[FF D8 FF E0 00 1...|    0|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54475|[FF D8 FF E0 00 1...|    0|\n",
      "+--------------------+--------------------+------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaryFilesDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "de490aa4-bf63-4638-876c-045bc11d3307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "binaryFilesDF2: org.apache.spark.sql.DataFrame = [path: string, modificationTime: timestamp ... 2 more fields]\n"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val binaryFilesDF2 = spark.read.format(\"binaryFile\")\n",
    ".option(\"pathGlobFilter\", \"*.jpg\") // le dices el tipo de formato\n",
    ".option(\"recursiveFileLookup\",\"true\")\n",
    ".load(\"ejemploIMAGE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb15558-1dbc-45da-bdec-cfc8dad9eb8e",
   "metadata": {},
   "source": [
    "Notemos que la columna label desaparece cuando recursiveFileLookup es true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d5211d4e-1c33-4444-a4d7-dfe70d01fb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+\n",
      "|                path|    modificationTime|length|             content|\n",
      "+--------------------+--------------------+------+--------------------+\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 55037|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...| 2022-06-23 10:05:09| 54634|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54624|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54505|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54475|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54449|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54440|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54377|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:05:...| 54365|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:05:...| 54330|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54289|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54263|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54252|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54248|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:05:...| 54244|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54225|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:05:...| 54200|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54190|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54178|[FF D8 FF E0 00 1...|\n",
      "|file:/home/jovyan...|2022-06-23 10:04:...| 54115|[FF D8 FF E0 00 1...|\n",
      "+--------------------+--------------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+\n",
      "|             content|\n",
      "+--------------------+\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "|[FF D8 FF E0 00 1...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binaryFilesDF2.show()\n",
    "binaryFilesDF2.select(col(\"content\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076aa2a-69ba-4e7b-b893-8e043df5f636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
