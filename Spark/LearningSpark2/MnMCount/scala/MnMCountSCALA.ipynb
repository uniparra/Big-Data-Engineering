{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffe945a-0a3c-4a22-a2fc-96303bb8ce55",
   "metadata": {},
   "source": [
    "<h2>MnMCount escrito en scala. Jupyter</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1507b-be21-4b4e-9ede-6d76b086e911",
   "metadata": {},
   "source": [
    "_Comenzamos por iniciar una SparkSession que es el objeto principal o la base a partir de la cual cuelga toda la funcionalidad de Apache Spark. Es similar al SparkContext de los RDD, pero en este caso, para trabajar con SparkSQL, los DataFrame y DataSet_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f95c9bf-5b91-4016-a7a9-ca60bdd9d479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2697e5d1\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    ".builder\n",
    ".appName(\"MnMCountScala\")\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07e46ce2-d430-4d39-805d-0f24494f4707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnmfile: String = mnm_dataset.csv\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mnmfile = \"mnm_dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16278a61-ba99-44d7-9589-fb715a0083dd",
   "metadata": {},
   "source": [
    "_Leemos el csv indicando (_ `.option(\"header\",\"true\")` _) header=true para que la primera entrada de cada columna sea tomada como cabecera **ya que pordefecto este valor es header=false**._\n",
    "\n",
    "_Indicamos también que inferSchema=true (_ `.option(\"inferSchema\",\"true\")` _), es decir que se infiera del esquema (equiv. tabla) el tipo de dato que corresponde a cada columna, **ya que por defecto inferSchema=false**, en este caso lo que hace es tratar todos los datos como_ `StringType`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669aeac9-5f80-4c4e-b660-e830c0bb68ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnmDF: org.apache.spark.sql.DataFrame = [State: string, Color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mnmDF=spark.read.format(\"csv\")\n",
    ".option(\"header\",\"true\")\n",
    ".option(\"inferSchema\",\"true\")\n",
    ".load(mnmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c29bfd2-6954-4f3b-893f-e9cb39ebe634",
   "metadata": {},
   "source": [
    "_Esto ya no es más que una consulta típica de SQL_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "838b91f0-2bab-4bbf-8b62-d76de50d8a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "countMnMDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [State: string, Color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val countMnMDF=mnmDF\n",
    ".select(\"State\",\"Color\",\"Count\")\n",
    ".groupBy(\"State\",\"Color\")\n",
    ".agg(count(\"Count\")\n",
    "     .alias(\"Total\"))\n",
    ".orderBy(desc(\"Total\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691f660c-cb3d-496f-b810-aefa2693de27",
   "metadata": {},
   "source": [
    "_Recordemos que en virtud del **lazy evaluation** todavía no se ha ejecutado nada, sino que se han recogido las **transformations** en un linaje para que al meter en juego una **action** se ejecuten las directrices de dicho grafo. Recordemos que cada **transformation** transforma un dataframe en otro dataframe. Acordarse tambien que hay:_\n",
    "    <ul>\n",
    "    <li> **narrow transformations**--> Se ejecutan en cada nodo y dan por si mismas el resultado </li>\n",
    "    <li>**wide transformations**--> Se ejecutan en cada nodo y luego han de convinarse para dar el resultado</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ff2b89f0-ac1b-4fe8-a9b7-4d8e9a064930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "|State| Color|Total|\n",
      "+-----+------+-----+\n",
      "|   CA|Yellow| 1807|\n",
      "|   WA| Green| 1779|\n",
      "|   OR|Orange| 1743|\n",
      "|   TX| Green| 1737|\n",
      "|   TX|   Red| 1725|\n",
      "|   CA| Green| 1723|\n",
      "|   CO|Yellow| 1721|\n",
      "|   CA| Brown| 1718|\n",
      "|   CO| Green| 1713|\n",
      "|   NV|Orange| 1712|\n",
      "|   TX|Yellow| 1703|\n",
      "|   NV| Green| 1698|\n",
      "|   AZ| Brown| 1698|\n",
      "|   WY| Green| 1695|\n",
      "|   CO|  Blue| 1695|\n",
      "|   NM|   Red| 1690|\n",
      "|   AZ|Orange| 1689|\n",
      "|   NM|Yellow| 1688|\n",
      "|   NM| Brown| 1687|\n",
      "|   UT|Orange| 1684|\n",
      "|   NM| Green| 1682|\n",
      "|   UT|   Red| 1680|\n",
      "|   AZ| Green| 1676|\n",
      "|   NV|Yellow| 1675|\n",
      "|   NV|  Blue| 1673|\n",
      "|   WA|   Red| 1671|\n",
      "|   WY|   Red| 1670|\n",
      "|   WA| Brown| 1669|\n",
      "|   NM|Orange| 1665|\n",
      "|   WY|  Blue| 1664|\n",
      "|   WA|Yellow| 1663|\n",
      "|   WA|Orange| 1658|\n",
      "|   CA|Orange| 1657|\n",
      "|   NV| Brown| 1657|\n",
      "|   CA|   Red| 1656|\n",
      "|   CO| Brown| 1656|\n",
      "|   UT|  Blue| 1655|\n",
      "|   AZ|Yellow| 1654|\n",
      "|   TX|Orange| 1652|\n",
      "|   AZ|   Red| 1648|\n",
      "|   OR|  Blue| 1646|\n",
      "|   UT|Yellow| 1645|\n",
      "|   OR|   Red| 1645|\n",
      "|   CO|Orange| 1642|\n",
      "|   TX| Brown| 1641|\n",
      "|   NM|  Blue| 1638|\n",
      "|   AZ|  Blue| 1636|\n",
      "|   OR| Green| 1634|\n",
      "|   UT| Brown| 1631|\n",
      "|   WY|Yellow| 1626|\n",
      "|   WA|  Blue| 1625|\n",
      "|   CO|   Red| 1624|\n",
      "|   OR| Brown| 1621|\n",
      "|   TX|  Blue| 1614|\n",
      "|   OR|Yellow| 1614|\n",
      "|   NV|   Red| 1610|\n",
      "|   CA|  Blue| 1603|\n",
      "|   WY|Orange| 1595|\n",
      "|   UT| Green| 1591|\n",
      "|   WY| Brown| 1532|\n",
      "+-----+------+-----+\n",
      "\n",
      "total Rows = 60\n"
     ]
    }
   ],
   "source": [
    "countMnMDF.show(60)\n",
    "println(s\"total Rows = ${countMnMDF.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a6c6c-f4dc-4e73-ae2d-284f3264cc22",
   "metadata": {},
   "source": [
    "_Cerramos la SparkSession_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a455e66-9590-4c98-874d-445d50e25f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7640d858-a1ed-499f-acf3-e09ffe59ef9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
